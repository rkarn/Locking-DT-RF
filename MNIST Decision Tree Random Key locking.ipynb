{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data from yann lecunn dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yann Lecunn dataset is of the format idx and split across 4 files \n",
    "1. train-images.idx3-ubyte : training image set which consists of 60000 images each image is represented by a 28*28 array\n",
    "2. train-labels.idx1-ubyte : training label set which consists of 60000 labels \n",
    "3. t10k-images.idx3-ubyte : test image set which consists of 10000 images each image is represented by a 28*28\n",
    "4. t10k-labels.idx1-ubyte : training label set which consists of 10000 labels\n",
    "\n",
    "Get the dataset from http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import idx2numpy\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_3D = idx2numpy.convert_from_file('/root/decision-tree-python/train-images.idx3-ubyte')\n",
    "X_train = X_train_3D.flatten().reshape(60000,784)\n",
    "\n",
    "y_train = idx2numpy.convert_from_file('/root/decision-tree-python/train-labels.idx1-ubyte')\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_3D = idx2numpy.convert_from_file('/root/decision-tree-python/t10k-images.idx3-ubyte')\n",
    "X_test =  X_test_3D.flatten().reshape(10000,784)\n",
    "\n",
    "y_test = idx2numpy.convert_from_file('/root/decision-tree-python/t10k-labels.idx1-ubyte')\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=8)\n",
      "Number of nodes in the decision tree 507.\n",
      "Number of threshold in the decision tree 507.\n",
      "Number of leaves in the decision tree 254.\n",
      "0.8232 0.83208\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "X_shuffle,y_shuffle = shuffle(X_train,y_train)\n",
    "X_train = X_shuffle[0:50000]\n",
    "y_train = y_shuffle[0:50000]\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "#dt_clf = tree.DecisionTreeClassifier(max_depth=20, max_leaf_nodes=300)\n",
    "#dt_clf = tree.DecisionTreeClassifier(max_depth=4, max_leaf_nodes=20)\n",
    "dt_clf = tree.DecisionTreeClassifier(max_depth=8)\n",
    "\n",
    "#y_train_pred = cross_val_predict(dt_clf, X_train, y_train, cv=2)\n",
    "print(dt_clf.fit(X_train, y_train))\n",
    "\n",
    "print('Number of nodes in the decision tree {}.'.format(dt_clf.tree_.node_count))\n",
    "print('Number of threshold in the decision tree {}.'.format(len(dt_clf.tree_.threshold)))\n",
    "print('Number of leaves in the decision tree {}.'.format(dt_clf.tree_.n_leaves))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, dt_clf.predict(X_test)), accuracy_score(y_train, dt_clf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max and Min values of thresholds in decision tree are 253 -2\n"
     ]
    }
   ],
   "source": [
    "threshold = dt_clf.tree_.threshold\n",
    "import pandas as pd\n",
    "df_train = pd.DataFrame(data = X_train, columns = range(X_train[0].shape[0]))\n",
    "df_test = pd.DataFrame(data = X_test, columns = range(X_test[0].shape[0]))\n",
    "df_train.shape, df_test.shape\n",
    "df = pd.concat([df_train, df_test])\n",
    "unique_vals = []\n",
    "for i in df.columns:\n",
    "    unique_vals.append(df[i].unique())\n",
    "flatten_list = np.concatenate(unique_vals).ravel()\n",
    "print('Max and Min values of thresholds in decision tree are', max([int(i) for i in list(set(threshold))]), min([int(i) for i in list(set(threshold))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Displaying the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_350 <= 131.50\n",
      "|   |--- feature_568 <= 0.50\n",
      "|   |   |--- feature_430 <= 0.50\n",
      "|   |   |   |--- feature_405 <= 4.50\n",
      "|   |   |   |   |--- feature_485 <= 12.50\n",
      "|   |   |   |   |   |--- feature_154 <= 0.50\n",
      "|   |   |   |   |   |   |--- feature_594 <= 21.50\n",
      "|   |   |   |   |   |   |   |--- feature_156 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_156 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_594 >  21.50\n",
      "|   |   |   |   |   |   |   |--- feature_408 <= 15.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_408 >  15.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |--- feature_154 >  0.50\n",
      "|   |   |   |   |   |   |--- feature_566 <= 85.50\n",
      "|   |   |   |   |   |   |   |--- feature_571 <= 4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_571 >  4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_566 >  85.50\n",
      "|   |   |   |   |   |   |   |--- feature_399 <= 17.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_399 >  17.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_485 >  12.50\n",
      "|   |   |   |   |   |--- feature_211 <= 9.50\n",
      "|   |   |   |   |   |   |--- feature_543 <= 171.00\n",
      "|   |   |   |   |   |   |   |--- feature_294 <= 8.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_294 >  8.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |--- feature_543 >  171.00\n",
      "|   |   |   |   |   |   |   |--- feature_217 <= 2.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_217 >  2.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |--- feature_211 >  9.50\n",
      "|   |   |   |   |   |   |--- feature_427 <= 0.50\n",
      "|   |   |   |   |   |   |   |--- feature_154 <= 1.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_154 >  1.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_427 >  0.50\n",
      "|   |   |   |   |   |   |   |--- feature_437 <= 1.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_437 >  1.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |--- feature_405 >  4.50\n",
      "|   |   |   |   |--- feature_516 <= 2.50\n",
      "|   |   |   |   |   |--- feature_353 <= 0.50\n",
      "|   |   |   |   |   |   |--- feature_322 <= 6.50\n",
      "|   |   |   |   |   |   |   |--- feature_355 <= 12.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_355 >  12.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- feature_322 >  6.50\n",
      "|   |   |   |   |   |   |   |--- feature_546 <= 2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_546 >  2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |--- feature_353 >  0.50\n",
      "|   |   |   |   |   |   |--- feature_652 <= 57.50\n",
      "|   |   |   |   |   |   |   |--- feature_210 <= 25.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_210 >  25.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |--- feature_652 >  57.50\n",
      "|   |   |   |   |   |   |   |--- feature_319 <= 149.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_319 >  149.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |--- feature_516 >  2.50\n",
      "|   |   |   |   |   |--- feature_376 <= 3.50\n",
      "|   |   |   |   |   |   |--- feature_235 <= 1.00\n",
      "|   |   |   |   |   |   |   |--- feature_150 <= 4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_150 >  4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_235 >  1.00\n",
      "|   |   |   |   |   |   |   |--- feature_710 <= 20.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_710 >  20.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |--- feature_376 >  3.50\n",
      "|   |   |   |   |   |   |--- feature_658 <= 5.50\n",
      "|   |   |   |   |   |   |   |--- feature_127 <= 14.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_127 >  14.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_658 >  5.50\n",
      "|   |   |   |   |   |   |   |--- feature_434 <= 30.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_434 >  30.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |--- feature_430 >  0.50\n",
      "|   |   |   |--- feature_211 <= 28.50\n",
      "|   |   |   |   |--- feature_98 <= 0.50\n",
      "|   |   |   |   |   |--- feature_267 <= 121.00\n",
      "|   |   |   |   |   |   |--- feature_95 <= 7.00\n",
      "|   |   |   |   |   |   |   |--- feature_155 <= 87.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_155 >  87.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_95 >  7.00\n",
      "|   |   |   |   |   |   |   |--- feature_242 <= 104.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_242 >  104.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |--- feature_267 >  121.00\n",
      "|   |   |   |   |   |   |--- feature_381 <= 2.50\n",
      "|   |   |   |   |   |   |   |--- feature_412 <= 3.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_412 >  3.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |--- feature_381 >  2.50\n",
      "|   |   |   |   |   |   |   |--- feature_406 <= 35.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_406 >  35.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |--- feature_98 >  0.50\n",
      "|   |   |   |   |   |--- feature_537 <= 8.00\n",
      "|   |   |   |   |   |   |--- feature_242 <= 44.50\n",
      "|   |   |   |   |   |   |   |--- feature_272 <= 116.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_272 >  116.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- feature_242 >  44.50\n",
      "|   |   |   |   |   |   |   |--- feature_345 <= 58.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_345 >  58.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_537 >  8.00\n",
      "|   |   |   |   |   |   |--- feature_375 <= 218.50\n",
      "|   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_375 >  218.50\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |--- feature_211 >  28.50\n",
      "|   |   |   |   |--- feature_156 <= 0.50\n",
      "|   |   |   |   |   |--- feature_381 <= 2.50\n",
      "|   |   |   |   |   |   |--- feature_217 <= 1.50\n",
      "|   |   |   |   |   |   |   |--- feature_542 <= 70.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_542 >  70.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_217 >  1.50\n",
      "|   |   |   |   |   |   |   |--- feature_412 <= 53.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_412 >  53.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |--- feature_381 >  2.50\n",
      "|   |   |   |   |   |   |--- feature_317 <= 0.50\n",
      "|   |   |   |   |   |   |   |--- feature_342 <= 1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_342 >  1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |--- feature_317 >  0.50\n",
      "|   |   |   |   |   |   |   |--- feature_543 <= 189.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_543 >  189.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |--- feature_156 >  0.50\n",
      "|   |   |   |   |   |--- feature_101 <= 1.00\n",
      "|   |   |   |   |   |   |--- feature_656 <= 1.50\n",
      "|   |   |   |   |   |   |   |--- feature_572 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_572 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_656 >  1.50\n",
      "|   |   |   |   |   |   |   |--- feature_434 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_434 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |--- feature_101 >  1.00\n",
      "|   |   |   |   |   |   |--- feature_188 <= 146.50\n",
      "|   |   |   |   |   |   |   |--- feature_571 <= 1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_571 >  1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_188 >  146.50\n",
      "|   |   |   |   |   |   |   |--- feature_317 <= 59.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_317 >  59.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |--- feature_568 >  0.50\n",
      "|   |   |--- feature_435 <= 0.50\n",
      "|   |   |   |--- feature_489 <= 22.50\n",
      "|   |   |   |   |--- feature_380 <= 2.50\n",
      "|   |   |   |   |   |--- feature_324 <= 173.00\n",
      "|   |   |   |   |   |   |--- feature_72 <= 1.00\n",
      "|   |   |   |   |   |   |   |--- feature_455 <= 1.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_455 >  1.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_72 >  1.00\n",
      "|   |   |   |   |   |   |   |--- feature_440 <= 67.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_440 >  67.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |--- feature_324 >  173.00\n",
      "|   |   |   |   |   |   |--- feature_271 <= 11.00\n",
      "|   |   |   |   |   |   |   |--- feature_267 <= 125.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_267 >  125.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_271 >  11.00\n",
      "|   |   |   |   |   |   |   |--- feature_455 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_455 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_380 >  2.50\n",
      "|   |   |   |   |   |--- feature_298 <= 116.00\n",
      "|   |   |   |   |   |   |--- feature_485 <= 94.00\n",
      "|   |   |   |   |   |   |   |--- feature_376 <= 71.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_376 >  71.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |--- feature_485 >  94.00\n",
      "|   |   |   |   |   |   |   |--- feature_296 <= 118.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_296 >  118.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_298 >  116.00\n",
      "|   |   |   |   |   |   |--- feature_406 <= 43.50\n",
      "|   |   |   |   |   |   |   |--- feature_237 <= 1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_237 >  1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_406 >  43.50\n",
      "|   |   |   |   |   |   |   |--- feature_294 <= 91.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_294 >  91.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |--- feature_489 >  22.50\n",
      "|   |   |   |   |--- feature_319 <= 1.00\n",
      "|   |   |   |   |   |--- feature_344 <= 84.00\n",
      "|   |   |   |   |   |   |--- feature_377 <= 18.00\n",
      "|   |   |   |   |   |   |   |--- feature_685 <= 27.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_685 >  27.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |--- feature_377 >  18.00\n",
      "|   |   |   |   |   |   |   |--- feature_354 <= 99.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_354 >  99.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |--- feature_344 >  84.00\n",
      "|   |   |   |   |   |   |--- feature_510 <= 86.50\n",
      "|   |   |   |   |   |   |   |--- feature_380 <= 15.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_380 >  15.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_510 >  86.50\n",
      "|   |   |   |   |   |   |   |--- feature_599 <= 29.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_599 >  29.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_319 >  1.00\n",
      "|   |   |   |   |   |--- feature_358 <= 42.50\n",
      "|   |   |   |   |   |   |--- feature_513 <= 40.50\n",
      "|   |   |   |   |   |   |   |--- feature_410 <= 2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_410 >  2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_513 >  40.50\n",
      "|   |   |   |   |   |   |   |--- feature_433 <= 239.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_433 >  239.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |--- feature_358 >  42.50\n",
      "|   |   |   |   |   |   |--- feature_427 <= 6.50\n",
      "|   |   |   |   |   |   |   |--- feature_537 <= 77.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_537 >  77.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_427 >  6.50\n",
      "|   |   |   |   |   |   |   |--- feature_97 <= 85.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_97 >  85.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |--- feature_435 >  0.50\n",
      "|   |   |   |--- feature_347 <= 0.50\n",
      "|   |   |   |   |--- feature_344 <= 27.50\n",
      "|   |   |   |   |   |--- feature_155 <= 0.50\n",
      "|   |   |   |   |   |   |--- feature_652 <= 1.00\n",
      "|   |   |   |   |   |   |   |--- feature_490 <= 103.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_490 >  103.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_652 >  1.00\n",
      "|   |   |   |   |   |   |   |--- feature_238 <= 2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_238 >  2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |--- feature_155 >  0.50\n",
      "|   |   |   |   |   |   |--- feature_684 <= 2.00\n",
      "|   |   |   |   |   |   |   |--- feature_349 <= 134.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_349 >  134.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_684 >  2.00\n",
      "|   |   |   |   |   |   |   |--- feature_514 <= 58.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_514 >  58.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |--- feature_344 >  27.50\n",
      "|   |   |   |   |   |--- feature_214 <= 4.50\n",
      "|   |   |   |   |   |   |--- feature_267 <= 9.50\n",
      "|   |   |   |   |   |   |   |--- feature_217 <= 53.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_217 >  53.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- feature_267 >  9.50\n",
      "|   |   |   |   |   |   |   |--- feature_248 <= 35.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_248 >  35.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |--- feature_214 >  4.50\n",
      "|   |   |   |   |   |   |--- feature_402 <= 33.50\n",
      "|   |   |   |   |   |   |   |--- feature_399 <= 5.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_399 >  5.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |--- feature_402 >  33.50\n",
      "|   |   |   |   |   |   |   |--- feature_514 <= 6.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_514 >  6.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |--- feature_347 >  0.50\n",
      "|   |   |   |   |--- feature_655 <= 0.50\n",
      "|   |   |   |   |   |--- feature_271 <= 1.00\n",
      "|   |   |   |   |   |   |--- feature_484 <= 0.50\n",
      "|   |   |   |   |   |   |   |--- feature_515 <= 52.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_515 >  52.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_484 >  0.50\n",
      "|   |   |   |   |   |   |   |--- feature_219 <= 2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_219 >  2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |--- feature_271 >  1.00\n",
      "|   |   |   |   |   |   |--- feature_354 <= 10.50\n",
      "|   |   |   |   |   |   |   |--- feature_385 <= 4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_385 >  4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_354 >  10.50\n",
      "|   |   |   |   |   |   |   |--- feature_156 <= 14.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_156 >  14.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |--- feature_655 >  0.50\n",
      "|   |   |   |   |   |--- feature_354 <= 0.50\n",
      "|   |   |   |   |   |   |--- feature_515 <= 85.50\n",
      "|   |   |   |   |   |   |   |--- feature_513 <= 184.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_513 >  184.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |--- feature_515 >  85.50\n",
      "|   |   |   |   |   |   |   |--- feature_523 <= 3.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_523 >  3.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |--- feature_354 >  0.50\n",
      "|   |   |   |   |   |   |--- feature_433 <= 1.00\n",
      "|   |   |   |   |   |   |   |--- feature_457 <= 44.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_457 >  44.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_433 >  1.00\n",
      "|   |   |   |   |   |   |   |--- feature_514 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_514 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|--- feature_350 >  131.50\n",
      "|   |--- feature_489 <= 25.50\n",
      "|   |   |--- feature_290 <= 34.50\n",
      "|   |   |   |--- feature_486 <= 58.50\n",
      "|   |   |   |   |--- feature_490 <= 120.50\n",
      "|   |   |   |   |   |--- feature_315 <= 61.00\n",
      "|   |   |   |   |   |   |--- feature_180 <= 0.50\n",
      "|   |   |   |   |   |   |   |--- feature_126 <= 68.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_126 >  68.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_180 >  0.50\n",
      "|   |   |   |   |   |   |   |--- feature_264 <= 149.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_264 >  149.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |--- feature_315 >  61.00\n",
      "|   |   |   |   |   |   |--- feature_296 <= 1.00\n",
      "|   |   |   |   |   |   |   |--- feature_300 <= 15.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_300 >  15.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- feature_296 >  1.00\n",
      "|   |   |   |   |   |   |   |--- feature_627 <= 4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_627 >  4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |--- feature_490 >  120.50\n",
      "|   |   |   |   |   |--- feature_269 <= 19.00\n",
      "|   |   |   |   |   |   |--- feature_627 <= 5.00\n",
      "|   |   |   |   |   |   |   |--- feature_204 <= 18.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_204 >  18.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |--- feature_627 >  5.00\n",
      "|   |   |   |   |   |   |   |--- feature_606 <= 13.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_606 >  13.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_269 >  19.00\n",
      "|   |   |   |   |   |   |--- feature_153 <= 49.00\n",
      "|   |   |   |   |   |   |   |--- feature_245 <= 19.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_245 >  19.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |--- feature_153 >  49.00\n",
      "|   |   |   |   |   |   |   |--- feature_323 <= 58.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_323 >  58.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |--- feature_486 >  58.50\n",
      "|   |   |   |   |--- feature_657 <= 5.00\n",
      "|   |   |   |   |   |--- feature_152 <= 16.50\n",
      "|   |   |   |   |   |   |--- feature_297 <= 47.50\n",
      "|   |   |   |   |   |   |   |--- feature_601 <= 67.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_601 >  67.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_297 >  47.50\n",
      "|   |   |   |   |   |   |   |--- feature_384 <= 74.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_384 >  74.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_152 >  16.50\n",
      "|   |   |   |   |   |   |--- feature_344 <= 63.50\n",
      "|   |   |   |   |   |   |   |--- feature_439 <= 54.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_439 >  54.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_344 >  63.50\n",
      "|   |   |   |   |   |   |   |--- feature_383 <= 1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_383 >  1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |--- feature_657 >  5.00\n",
      "|   |   |   |   |   |--- feature_439 <= 12.50\n",
      "|   |   |   |   |   |   |--- feature_464 <= 1.00\n",
      "|   |   |   |   |   |   |   |--- feature_125 <= 11.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_125 >  11.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_464 >  1.00\n",
      "|   |   |   |   |   |   |   |--- feature_431 <= 2.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_431 >  2.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |--- feature_439 >  12.50\n",
      "|   |   |   |   |   |   |--- feature_179 <= 12.50\n",
      "|   |   |   |   |   |   |   |--- feature_352 <= 17.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_352 >  17.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_179 >  12.50\n",
      "|   |   |   |   |   |   |   |--- feature_315 <= 11.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_315 >  11.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |--- feature_290 >  34.50\n",
      "|   |   |   |--- feature_297 <= 9.50\n",
      "|   |   |   |   |--- feature_486 <= 58.00\n",
      "|   |   |   |   |   |--- feature_186 <= 2.50\n",
      "|   |   |   |   |   |   |--- feature_293 <= 217.50\n",
      "|   |   |   |   |   |   |   |--- feature_464 <= 51.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_464 >  51.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- feature_293 >  217.50\n",
      "|   |   |   |   |   |   |   |--- feature_463 <= 225.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_463 >  225.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_186 >  2.50\n",
      "|   |   |   |   |   |   |--- feature_301 <= 44.00\n",
      "|   |   |   |   |   |   |   |--- feature_294 <= 251.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_294 >  251.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_301 >  44.00\n",
      "|   |   |   |   |   |   |   |--- feature_381 <= 13.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_381 >  13.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |--- feature_486 >  58.00\n",
      "|   |   |   |   |   |--- feature_656 <= 5.00\n",
      "|   |   |   |   |   |   |--- feature_430 <= 84.00\n",
      "|   |   |   |   |   |   |   |--- feature_319 <= 251.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_319 >  251.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |--- feature_430 >  84.00\n",
      "|   |   |   |   |   |   |   |--- feature_571 <= 3.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_571 >  3.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |--- feature_656 >  5.00\n",
      "|   |   |   |   |   |   |--- feature_373 <= 15.00\n",
      "|   |   |   |   |   |   |   |--- feature_432 <= 39.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_432 >  39.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_373 >  15.00\n",
      "|   |   |   |   |   |   |   |--- feature_300 <= 16.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_300 >  16.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_297 >  9.50\n",
      "|   |   |   |   |--- feature_598 <= 0.50\n",
      "|   |   |   |   |   |--- feature_210 <= 4.50\n",
      "|   |   |   |   |   |   |--- feature_321 <= 208.00\n",
      "|   |   |   |   |   |   |   |--- feature_408 <= 168.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_408 >  168.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- feature_321 >  208.00\n",
      "|   |   |   |   |   |   |   |--- feature_486 <= 13.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_486 >  13.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |--- feature_210 >  4.50\n",
      "|   |   |   |   |   |   |--- feature_653 <= 78.00\n",
      "|   |   |   |   |   |   |   |--- feature_155 <= 3.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_155 >  3.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_653 >  78.00\n",
      "|   |   |   |   |   |   |   |--- feature_596 <= 66.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_596 >  66.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |--- feature_598 >  0.50\n",
      "|   |   |   |   |   |--- feature_486 <= 9.50\n",
      "|   |   |   |   |   |   |--- feature_427 <= 205.50\n",
      "|   |   |   |   |   |   |   |--- feature_269 <= 1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_269 >  1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_427 >  205.50\n",
      "|   |   |   |   |   |   |   |--- feature_380 <= 224.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_380 >  224.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |--- feature_486 >  9.50\n",
      "|   |   |   |   |   |   |--- feature_400 <= 28.00\n",
      "|   |   |   |   |   |   |   |--- feature_431 <= 3.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_431 >  3.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_400 >  28.00\n",
      "|   |   |   |   |   |   |   |--- feature_241 <= 42.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_241 >  42.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |--- feature_489 >  25.50\n",
      "|   |   |--- feature_521 <= 0.50\n",
      "|   |   |   |--- feature_347 <= 2.50\n",
      "|   |   |   |   |--- feature_206 <= 4.50\n",
      "|   |   |   |   |   |--- feature_328 <= 0.50\n",
      "|   |   |   |   |   |   |--- feature_608 <= 1.00\n",
      "|   |   |   |   |   |   |   |--- feature_438 <= 8.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_438 >  8.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_608 >  1.00\n",
      "|   |   |   |   |   |   |   |--- feature_123 <= 22.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_123 >  22.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |--- feature_328 >  0.50\n",
      "|   |   |   |   |   |   |--- feature_238 <= 2.00\n",
      "|   |   |   |   |   |   |   |--- feature_624 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_624 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_238 >  2.00\n",
      "|   |   |   |   |   |   |   |--- feature_296 <= 232.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_296 >  232.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_206 >  4.50\n",
      "|   |   |   |   |   |--- feature_713 <= 2.50\n",
      "|   |   |   |   |   |   |--- feature_515 <= 6.00\n",
      "|   |   |   |   |   |   |   |--- feature_431 <= 4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_431 >  4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_515 >  6.00\n",
      "|   |   |   |   |   |   |   |--- feature_372 <= 26.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_372 >  26.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |--- feature_713 >  2.50\n",
      "|   |   |   |   |   |   |--- feature_633 <= 15.50\n",
      "|   |   |   |   |   |   |   |--- feature_461 <= 72.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_461 >  72.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |--- feature_633 >  15.50\n",
      "|   |   |   |   |   |   |   |--- feature_627 <= 36.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_627 >  36.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |--- feature_347 >  2.50\n",
      "|   |   |   |   |--- feature_460 <= 16.50\n",
      "|   |   |   |   |   |--- feature_212 <= 62.50\n",
      "|   |   |   |   |   |   |--- feature_542 <= 5.00\n",
      "|   |   |   |   |   |   |   |--- feature_321 <= 202.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_321 >  202.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |--- feature_542 >  5.00\n",
      "|   |   |   |   |   |   |   |--- feature_409 <= 247.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_409 >  247.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |--- feature_212 >  62.50\n",
      "|   |   |   |   |   |   |--- feature_156 <= 5.50\n",
      "|   |   |   |   |   |   |   |--- feature_568 <= 20.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_568 >  20.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |--- feature_156 >  5.50\n",
      "|   |   |   |   |   |   |   |--- feature_242 <= 1.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_242 >  1.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |--- feature_460 >  16.50\n",
      "|   |   |   |   |   |--- feature_322 <= 245.50\n",
      "|   |   |   |   |   |   |--- feature_657 <= 1.50\n",
      "|   |   |   |   |   |   |   |--- feature_577 <= 240.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_577 >  240.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_657 >  1.50\n",
      "|   |   |   |   |   |   |   |--- feature_514 <= 10.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_514 >  10.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |--- feature_322 >  245.50\n",
      "|   |   |   |   |   |   |--- feature_374 <= 10.00\n",
      "|   |   |   |   |   |   |   |--- feature_273 <= 42.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_273 >  42.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_374 >  10.00\n",
      "|   |   |   |   |   |   |   |--- feature_275 <= 28.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_275 >  28.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |--- feature_521 >  0.50\n",
      "|   |   |   |--- feature_658 <= 0.50\n",
      "|   |   |   |   |--- feature_555 <= 7.50\n",
      "|   |   |   |   |   |--- feature_601 <= 3.50\n",
      "|   |   |   |   |   |   |--- feature_661 <= 1.00\n",
      "|   |   |   |   |   |   |   |--- feature_383 <= 8.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_383 >  8.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_661 >  1.00\n",
      "|   |   |   |   |   |   |   |--- feature_487 <= 5.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_487 >  5.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |--- feature_601 >  3.50\n",
      "|   |   |   |   |   |   |--- feature_654 <= 5.50\n",
      "|   |   |   |   |   |   |   |--- feature_430 <= 71.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_430 >  71.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_654 >  5.50\n",
      "|   |   |   |   |   |   |   |--- feature_552 <= 5.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_552 >  5.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |--- feature_555 >  7.50\n",
      "|   |   |   |   |   |--- feature_371 <= 120.50\n",
      "|   |   |   |   |   |   |--- feature_410 <= 253.50\n",
      "|   |   |   |   |   |   |   |--- feature_715 <= 31.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_715 >  31.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- feature_410 >  253.50\n",
      "|   |   |   |   |   |   |   |--- feature_381 <= 252.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_381 >  252.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |--- feature_371 >  120.50\n",
      "|   |   |   |   |   |   |--- feature_574 <= 102.50\n",
      "|   |   |   |   |   |   |   |--- feature_384 <= 124.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_384 >  124.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- feature_574 >  102.50\n",
      "|   |   |   |   |   |   |   |--- feature_213 <= 228.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_213 >  228.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |--- feature_658 >  0.50\n",
      "|   |   |   |   |--- feature_515 <= 55.50\n",
      "|   |   |   |   |   |--- feature_270 <= 3.00\n",
      "|   |   |   |   |   |   |--- feature_547 <= 228.50\n",
      "|   |   |   |   |   |   |   |--- feature_544 <= 13.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_544 >  13.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_547 >  228.50\n",
      "|   |   |   |   |   |   |   |--- feature_467 <= 2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_467 >  2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |--- feature_270 >  3.00\n",
      "|   |   |   |   |   |   |--- feature_318 <= 33.50\n",
      "|   |   |   |   |   |   |   |--- feature_404 <= 52.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_404 >  52.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_318 >  33.50\n",
      "|   |   |   |   |   |   |   |--- feature_410 <= 68.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_410 >  68.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |--- feature_515 >  55.50\n",
      "|   |   |   |   |   |--- feature_546 <= 196.50\n",
      "|   |   |   |   |   |   |--- feature_440 <= 88.50\n",
      "|   |   |   |   |   |   |   |--- feature_555 <= 10.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_555 >  10.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_440 >  88.50\n",
      "|   |   |   |   |   |   |   |--- feature_290 <= 56.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_290 >  56.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |--- feature_546 >  196.50\n",
      "|   |   |   |   |   |   |--- feature_243 <= 21.50\n",
      "|   |   |   |   |   |   |   |--- feature_261 <= 12.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_261 >  12.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |--- feature_243 >  21.50\n",
      "|   |   |   |   |   |   |   |--- feature_434 <= 187.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_434 >  187.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      " [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_text\n",
    "text_representation = export_text(dt_clf)\n",
    "print(text_representation, dt_clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Circuit HDL: FSM Generator   (Run this cell twice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    \n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            print (\"{}{}:if ({} <= {})\".format(indent, node, name, int(round(threshold,3)))) \n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print (\"{}{}:else \".format(indent, node, name, int(round(threshold,3))))\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print (\"{} Label<={};\".format(indent, np.argmax(tree_.value[node][0],axis=0)))\n",
    "\n",
    "    recurse(0, 1)\n",
    "\n",
    "cols = range(784)\n",
    "features = ['pixels[{}]'.format(str(i)) for i in cols]\n",
    "class_names = [str(i) for i in dt_clf.classes_]\n",
    "tree_to_code(dt_clf, features)\n",
    "\n",
    "with open('verilog_newFSM.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "def write_file(data_towrite):\n",
    "    with open('verilog_file.v', 'a', encoding='utf-8') as file:\n",
    "        file.writelines(data_towrite)\n",
    "        file.close()\n",
    "               \n",
    "def clear_file():\n",
    "    with open('verilog_file.v', 'w', encoding='utf-8') as file:\n",
    "        pass\n",
    "        file.close()\n",
    "\n",
    "import itertools\n",
    "with open('verilog_newFSM.txt', 'r') as f:\n",
    "    tree_verilog = f.read()\n",
    "    f.close()\n",
    "\n",
    "clear_file()\n",
    "line_num = 0\n",
    "else_state = 0\n",
    "else_nextif_state = 0\n",
    "curr_line,next_line = itertools.tee(tree_verilog.split('\\n'))\n",
    "next(next_line, None)\n",
    "for i,j in list(zip(curr_line,next_line)):\n",
    "    if 'Label' in i:\n",
    "        pass\n",
    "        #write_file(f'  begin {i.strip()} state<=0;ml_inference_completed<=1; end \\n')\n",
    "    elif 'else' in i and 'Label' in j:\n",
    "        else_state = i.strip().split(':')[0]\n",
    "        line_num = search_content_file(' '+str(else_state)+':if' )\n",
    "        write_line_file(f'\\n       else begin {j.strip()} state<=0;ml_inference_completed<=1; end ', line_num)\n",
    "        #write_file(f'   {i.strip().split(\":\")[-1]} ')\n",
    "    elif 'else' in i and 'if' in j:\n",
    "        else_state = i.strip().split(':')[0]\n",
    "        else_nextif_state = j.strip().split(':')[0]\n",
    "        line_num = search_content_file(' '+str(else_state)+':if' )\n",
    "        write_line_file(f'else begin state<={else_nextif_state}; end ', line_num)\n",
    "    elif 'if' in i and 'Label' in j:\n",
    "        write_file(f'\\n {i.strip()} begin {j.strip()} state<=0;ml_inference_completed<=1; end ')\n",
    "    elif 'if' in i and 'if' in j:\n",
    "        write_file(f'\\n {i.strip()} begin state<={j.strip().split(\":\")[0]}; end \\n ')  \n",
    "update_stateformat_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying the number of \"if\", \"else\" and \"Label\" in verilog with decision tree architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of \"if\" statements 253.\n",
      "Number of \"else\" statements 253.\n",
      "Number of \"label\" statements 254.\n"
     ]
    }
   ],
   "source": [
    "#verifying that the number of \"if\" statements is one less than the number of nodes.\n",
    "file1 = open('verilog_file.v', 'r')\n",
    "contents = file1.readlines()\n",
    "counter_if =0\n",
    "for line in contents:\n",
    "    if 'if' in line:\n",
    "        counter_if = counter_if+1\n",
    "print('Number of \"if\" statements {}.'.format(counter_if))\n",
    "\n",
    "#verifying that the number of \"else\" statements is one less than the number of leaves.\n",
    "file1 = open('verilog_file.v', 'r')\n",
    "contents = file1.readlines()\n",
    "counter_else =0\n",
    "for line in contents:\n",
    "    if 'else' in line:\n",
    "        counter_else = counter_else+1\n",
    "print('Number of \"else\" statements {}.'.format(counter_else))\n",
    "\n",
    "#verifying that the number of \"Label\" statements is equal to the number of leaves.\n",
    "file1 = open('verilog_file.v', 'r')\n",
    "contents = file1.readlines()\n",
    "counter_return =0\n",
    "for line in contents:\n",
    "    if 'Label' in line:\n",
    "        counter_return = counter_return+1\n",
    "print('Number of \"label\" statements {}.'.format(counter_return))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the tree into the source code by rounding the threshold to nearest integer and save it in a py file. This is performed to verify the accuracy by using this dumped decision rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "#https://towardsdatascience.com/scikit-learn-decision-trees-explained-803f3812290d\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    print (\"def decision_tree_inference({}):\".format('feature_set'))\n",
    "    for i,pixel in enumerate(feature_names):\n",
    "            print (\"{}{}\".format(\"  \", pixel+'='+'feature_set['+str(i)+']'))\n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            print (\"{}if {} <= {}:\".format(indent, name, int(round(threshold,3))))  #convert the threshold to integer\n",
    "           \n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print (\"{}return {}\".format(indent, np.argmax(tree_.value[node][0],axis=0)))\n",
    "\n",
    "    recurse(0, 1)\n",
    "\n",
    "cols = range(784)\n",
    "features = ['pixel'+str(i) for i in cols]\n",
    "class_names = [str(i) for i in dt_clf.classes_]\n",
    "tree_to_code(dt_clf, features)\n",
    "\n",
    "with open('mnist_decision_tree_inference.py', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8232 0.83208\n"
     ]
    }
   ],
   "source": [
    "from mnist_decision_tree_inference import decision_tree_inference\n",
    "y_test_pred_tree = []\n",
    "for i,test_samples in enumerate(X_test):\n",
    "    y_test_pred_tree.append(decision_tree_inference(test_samples))\n",
    "\n",
    "y_train_pred_tree = []\n",
    "for i,test_samples in enumerate(X_train):\n",
    "    y_train_pred_tree.append(decision_tree_inference(test_samples))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_test_pred_tree), accuracy_score(y_train, y_train_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic Locking: XOR key gates at each node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "#https://towardsdatascience.com/scikit-learn-decision-trees-explained-803f3812290d\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    print (\"def dtLOCKED_AllXOR({},{}):\".format('feature_set','key'))\n",
    "    for i,pixel in enumerate(feature_names):\n",
    "            print (\"{}{}\".format(\"  \", pixel+'='+'feature_set['+str(i)+']'))\n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            #XOR Operation\n",
    "            print (\"{}if {} <= {} and ({} <= {}) ^ key==({} <= {})  :\".format(indent, name, int(round(threshold,3)),name, int(round(threshold,3)),name, int(round(threshold,3))))  #convert the threshold to integer\n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print (\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print (\"{}return {}\".format(indent, np.argmax(tree_.value[node][0],axis=0)))\n",
    "\n",
    "    recurse(0, 1)\n",
    "\n",
    "cols = range(784)\n",
    "features = ['pixel'+str(i) for i in cols]\n",
    "class_names = [str(i) for i in dt_clf.classes_]\n",
    "tree_to_code(dt_clf, features)\n",
    "\n",
    "with open('mnist_DTLock_AllXOR.py', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Verify the accuracy by using this dumped decision rules with correct/incorrect key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct key: 0.8232 0.83208\n",
      "Incorrect key: 0.0974 0.09692\n"
     ]
    }
   ],
   "source": [
    "from mnist_DTLock_AllXOR import dtLOCKED_AllXOR\n",
    "y_test_pred_tree = []\n",
    "for i,test_samples in enumerate(X_test):\n",
    "    y_test_pred_tree.append(dtLOCKED_AllXOR(test_samples,0))\n",
    "\n",
    "y_train_pred_tree = []\n",
    "for i,test_samples in enumerate(X_train):\n",
    "    y_train_pred_tree.append(dtLOCKED_AllXOR(test_samples,0))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Correct key:',accuracy_score(y_test, y_test_pred_tree), accuracy_score(y_train, y_train_pred_tree))\n",
    "\n",
    "y_test_pred_tree = []\n",
    "for i,test_samples in enumerate(X_test):\n",
    "    y_test_pred_tree.append(dtLOCKED_AllXOR(test_samples,1))\n",
    "\n",
    "y_train_pred_tree = []\n",
    "for i,test_samples in enumerate(X_train):\n",
    "    y_train_pred_tree.append(dtLOCKED_AllXOR(test_samples,1))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Incorrect key:',accuracy_score(y_test, y_test_pred_tree), accuracy_score(y_train, y_train_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic Locking: XNOR key gates at each node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "#https://towardsdatascience.com/scikit-learn-decision-trees-explained-803f3812290d\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    print (\"def dtLOCKED_AllXNOR({},{}):\".format('feature_set','key'))\n",
    "    for i,pixel in enumerate(feature_names):\n",
    "            print (\"{}{}\".format(\"  \", pixel+'='+'feature_set['+str(i)+']'))\n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            #XNOR Operation\n",
    "            print (\"{}if {} <= {} and not(({} <= {}) ^ key)==({} <= {})  :\".format(indent, name, int(round(threshold,3)),name, int(round(threshold,3)),name, int(round(threshold,3))))  #convert the threshold to integer\n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print (\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print (\"{}return {}\".format(indent, np.argmax(tree_.value[node][0],axis=0)))\n",
    "\n",
    "    recurse(0, 1)\n",
    "\n",
    "cols = range(784)\n",
    "features = ['pixel'+str(i) for i in cols]\n",
    "class_names = [str(i) for i in dt_clf.classes_]\n",
    "tree_to_code(dt_clf, features)\n",
    "\n",
    "with open('mnist_DTLock_AllXNOR.py', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Verify the accuracy by using this dumped decision rules with correct/incorrect key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct key: 0.8232 0.83208\n",
      "Incorrect key: 0.0974 0.09692\n"
     ]
    }
   ],
   "source": [
    "from mnist_DTLock_AllXNOR import dtLOCKED_AllXNOR\n",
    "y_test_pred_tree = []\n",
    "for i,test_samples in enumerate(X_test):\n",
    "    y_test_pred_tree.append(dtLOCKED_AllXNOR(test_samples,1))\n",
    "\n",
    "y_train_pred_tree = []\n",
    "for i,test_samples in enumerate(X_train):\n",
    "    y_train_pred_tree.append(dtLOCKED_AllXNOR(test_samples,1))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Correct key:',accuracy_score(y_test, y_test_pred_tree), accuracy_score(y_train, y_train_pred_tree))\n",
    "\n",
    "y_test_pred_tree = []\n",
    "for i,test_samples in enumerate(X_test):\n",
    "    y_test_pred_tree.append(dtLOCKED_AllXNOR(test_samples,0))\n",
    "\n",
    "y_train_pred_tree = []\n",
    "for i,test_samples in enumerate(X_train):\n",
    "    y_train_pred_tree.append(dtLOCKED_AllXNOR(test_samples,0))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Incorrect key:',accuracy_score(y_test, y_test_pred_tree), accuracy_score(y_train, y_train_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic Locking: Mix of XOR/XNOR key gates selected randomly at each node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Key generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 1 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1\n",
      " 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1\n",
      " 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 0 1 1 0\n",
      " 1 1 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1\n",
      " 1 1 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "key = np.random.randint(0,2,counter_if)\n",
    "print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Selecting gates between XOR and XNOR based on key value. 0-XOR, 1-XNOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "#https://towardsdatascience.com/scikit-learn-decision-trees-explained-803f3812290d\n",
    "from sklearn.tree import _tree\n",
    "def tree_to_code(tree, feature_names, key, key_counter):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    print (\"def dtLOCKED_XOR_XNOR({},{}):\".format('feature_set','key'))\n",
    "    for i,pixel in enumerate(feature_names):\n",
    "            print (\"{}{}\".format(\"  \", pixel+'='+'feature_set['+str(i)+']'))\n",
    "    def recurse(node, depth, key_counter):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            if key[key_counter] == 0:\n",
    "                print (\"{}if ({} <= {}) and (({} <= {}) ^ key[ ])==({} <= {})  :\".format(indent, name, int(round(threshold,3)),name, int(round(threshold,3)), name, int(round(threshold,3))))  #convert the threshold to integer\n",
    "            else:\n",
    "                print (\"{}if {} <= {} and not(({} <= {}) ^ key[ ])==({} <= {})  :\".format(indent, name, int(round(threshold,3)),name, int(round(threshold,3)), name, int(round(threshold,3))))  #convert the threshold to integer\n",
    "            key_counter = key_counter +1\n",
    "            recurse(tree_.children_left[node], depth + 1, key_counter)\n",
    "            print (\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_right[node], depth + 1, key_counter)\n",
    "        else:\n",
    "            print (\"{}return {}\".format(indent, np.argmax(tree_.value[node][0],axis=0)))\n",
    "\n",
    "    recurse(0, 1, key_counter)\n",
    "\n",
    "cols = range(784)\n",
    "features = ['pixel'+str(i) for i in cols]\n",
    "class_names = [str(i) for i in dt_clf.classes_]\n",
    "key_counter=0\n",
    "tree_to_code(dt_clf, features, key, key_counter)\n",
    "\n",
    "with open('mnist_DTLock_XOR_XNOR.py', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Adding appropirate XOR/XNOR for key value inside key[_] field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_key_lines(file_name):\n",
    "    with open(file_name, 'r') as file:\n",
    "        key_line_num = []\n",
    "        file_content = file.readlines()\n",
    "        for line_num,line in enumerate(file_content):\n",
    "            if 'key[ ]' in line:\n",
    "                key_line_num.append(line_num)        \n",
    "        return(key_line_num)\n",
    "\n",
    "def write_line_file(file_name, data_towrite, line_num):\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    file_content[line_num] = file_content[line_num].replace('key[ ]',f'key[{data_towrite}]')   \n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()\n",
    "    \n",
    "def correct_keygate_xor_xnor(file_name, key):\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    for line_num,line in enumerate(file_content):\n",
    "            if 'key[' in line:\n",
    "                key_index = int(line.split('key[')[1].split(']')[0])\n",
    "                if (key[key_index] == 1 and 'not' in line):\n",
    "                    pass\n",
    "                \n",
    "                if (key[key_index] == 1 and 'not' not in line):\n",
    "                    file_content[line_num] = ''.join(file_content[line_num].split('and')[0]+ 'and not' + file_content[line_num].split('and')[-1])\n",
    "                \n",
    "                if (key[key_index] == 0 and 'not' not in line):\n",
    "                    pass\n",
    "                \n",
    "                if (key[key_index] == 0 and 'not' in line):\n",
    "                    file_content[line_num] = file_content[line_num].replace('not','')\n",
    "                    \n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()\n",
    "                    \n",
    "def inspect_keygate_xor_xnor(file_name, key):\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    for line_num,line in enumerate(file_content):\n",
    "            if 'key[' in line:\n",
    "                key_index = int(line.split('key[')[1].split(']')[0])\n",
    "                if (key[key_index] == 1 and 'not' in line) or (key[key_index] == 0 and 'not' not in line):\n",
    "                    pass\n",
    "                else:\n",
    "                    pdb.set_trace()\n",
    "                    \n",
    "key_line_num = search_key_lines('mnist_DTLock_XOR_XNOR.py')\n",
    "for i,line_num in enumerate(key_line_num):\n",
    "    write_line_file('mnist_DTLock_XOR_XNOR.py', i, line_num)\n",
    "correct_keygate_xor_xnor('mnist_DTLock_XOR_XNOR.py', key)\n",
    "\n",
    "#Performing final inspection\n",
    "inspect_keygate_xor_xnor('mnist_DTLock_XOR_XNOR.py', key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Verify the accuracy by using this dumped decision rules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct key: 0.8232 0.83208\n"
     ]
    }
   ],
   "source": [
    "from mnist_DTLock_XOR_XNOR import dtLOCKED_XOR_XNOR\n",
    "y_test_pred_tree = []\n",
    "for i,test_samples in enumerate(X_test):\n",
    "    y_test_pred_tree.append(dtLOCKED_XOR_XNOR(test_samples,key))\n",
    "\n",
    "y_train_pred_tree = []\n",
    "for i,test_samples in enumerate(X_train):\n",
    "    y_train_pred_tree.append(dtLOCKED_XOR_XNOR(test_samples,key))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Correct key:',accuracy_score(y_test, y_test_pred_tree), accuracy_score(y_train, y_train_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Verify the accuracy by using this dumped decision rules with incorrect key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect key: 0.1085 0.17932\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_tree = []\n",
    "#shuffle the key list to simulate incorrect key\n",
    "np.random.shuffle(key)\n",
    "for i,test_samples in enumerate(X_test):\n",
    "    y_test_pred_tree.append(dtLOCKED_XOR_XNOR(test_samples,key))\n",
    "\n",
    "np.random.shuffle(key)\n",
    "y_train_pred_tree = []\n",
    "for i,test_samples in enumerate(X_train):\n",
    "    y_train_pred_tree.append(dtLOCKED_XOR_XNOR(test_samples,key))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Incorrect key:',accuracy_score(y_test, y_test_pred_tree), accuracy_score(y_train, y_train_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
